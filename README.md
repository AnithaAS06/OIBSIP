
# OIBSIP

# PROJECT 01(LEVEL 01)

## Supermart Grocery Sales â€“ Retail Analytics (EDA Project)
ğŸ“Œ Project Title

Exploratory Data Analysis (EDA) on Supermart Grocery Sales Dataset

ğŸ“– Project Description

This project performs Exploratory Data Analysis (EDA) on the Supermart Grocery Sales - Retail Analytics Dataset.

The objective of this analysis is to understand sales performance, customer behavior, product trends, regional distribution, and profitability patterns to generate meaningful business insights.

The analysis was implemented using Python in Jupyter Notebook.

ğŸ¯ Objectives

Analyze overall sales and profit performance

Identify top-performing categories and sub-categories

Study region-wise and state-wise sales trends

Analyze customer contribution to revenue

Examine the relationship between discount and profit

Perform time-based sales trend analysis

Provide business recommendations based on insights

ğŸ› ï¸ Tools & Technologies Used

Python

Jupyter Notebook

Pandas

NumPy

Matplotlib

ğŸ“‚ Dataset Information

Dataset Name:
Supermart Grocery Sales - Retail Analytics Dataset.csv

ğŸ“Š Dataset Columns:

Order ID

Customer Name

Category

Sub Category

City

Order Date

Region

Sales

Discount

Profit

State

ğŸ” Steps Performed in the Analysis
1ï¸âƒ£ Data Loading

The dataset was loaded using pandas and initial inspection was performed using:

head()

info()

describe()

2ï¸âƒ£ Data Cleaning

Removed duplicate records

Checked and handled missing values

Converted Order Date to datetime format

Ensured Sales and Profit were numeric

3ï¸âƒ£ Descriptive Analysis

Total Sales calculation

Total Profit calculation

Average Discount calculation

Statistical summary of numeric features

4ï¸âƒ£ Regional Analysis

Region-wise total sales

State-wise top-performing states

Visualization using bar charts

5ï¸âƒ£ Category & Sub-Category Analysis

Sales by Category

Sales by Sub Category

Profit comparison between categories

6ï¸âƒ£ Customer Analysis

Identified top 10 customers based on sales

Analyzed revenue contribution from customers

7ï¸âƒ£ Time Series Analysis

Extracted Month and Year from Order Date

Analyzed monthly sales trends

Visualized sales growth patterns

8ï¸âƒ£ Correlation Analysis

Studied relationship between:

Sales

Profit

Discount

Observed impact of discount on profitability

ğŸ“ˆ Key Insights

Certain regions contribute significantly higher sales.

A few categories generate the majority of revenue.

Higher discounts tend to reduce profit margins.

Sales show variation across months.

Top customers contribute a large portion of revenue.

ğŸ’¡ Business Recommendations

Focus marketing efforts on high-performing regions.

Optimize discount strategies to protect profit margins.

Increase inventory for high-demand categories.

Develop loyalty programs for top customers.

Improve performance in low-performing states.

âœ… Conclusion

This Exploratory Data Analysis helped uncover important sales patterns, customer behavior insights, and profitability trends within the Supermart Grocery dataset.

The findings can support data-driven decision-making to improve revenue growth and operational efficiency.

ğŸ‘©â€ğŸ’» Author

Internship Project â€“ Data Analysis
Anitha A S

# PROJECT 01(LEVEL 02)

# House Price Prediction using Linear Regression
ğŸ“Œ Project Title

Predicting House Prices using Linear Regression

ğŸ“– Project Description

This project focuses on building a machine learning model to predict house prices using Linear Regression.

The objective is to estimate house prices based on relevant features such as area, number of bedrooms, bathrooms, and other property-related attributes.

The model is implemented using Python in Jupyter Notebook and evaluated using standard regression metrics.

ğŸ¯ Objectives

Perform data exploration and cleaning

Select relevant features affecting house prices

Split the dataset into training and testing sets

Train a Linear Regression model

Evaluate model performance using MSE and RÂ² score

Visualize predicted vs actual values

Interpret model coefficients

ğŸ› ï¸ Tools & Technologies Used

Python

Jupyter Notebook

Pandas

NumPy

Matplotlib

Scikit-Learn

ğŸ“‚ Dataset Information

The dataset contains housing-related features and a target variable:

Example Features:

Area

Bedrooms

Bathrooms

Floors

Location (if available)

Price (Target Variable)

The target variable for prediction is:

â¡ House Price

ğŸ” Steps Performed
1ï¸âƒ£ Data Collection

The housing dataset was loaded into Jupyter Notebook using Pandas.

2ï¸âƒ£ Data Exploration

Checked dataset shape and structure

Viewed summary statistics

Identified data types

Checked for missing values

3ï¸âƒ£ Data Cleaning

Handled missing values

Ensured numeric format for features

Removed unnecessary columns

4ï¸âƒ£ Feature Selection

Selected independent variables (X) such as:

Area

Bedrooms

Bathrooms

Target variable (y):

Price

5ï¸âƒ£ Train-Test Split

The dataset was divided into:

80% Training data

20% Testing data

This ensures unbiased model evaluation.

6ï¸âƒ£ Model Training

A Linear Regression model from Scikit-Learn was trained using the training dataset.

7ï¸âƒ£ Model Evaluation

The model was evaluated using:

ğŸ“Œ Mean Squared Error (MSE)

ğŸ“Œ RÂ² Score

These metrics help measure prediction accuracy.

8ï¸âƒ£ Visualization

A scatter plot was created to compare:

Actual Prices

Predicted Prices

This helps visually assess model performance.

9ï¸âƒ£ Interpretation

Model coefficients were analyzed to understand:

Which features impact price the most

Whether features increase or decrease house price

ğŸ“ˆ Key Insights

House area has a strong positive relationship with price.

Additional bedrooms and bathrooms generally increase price.

The model demonstrates reasonable prediction capability based on RÂ² score.

Linear Regression effectively models the relationship between features and house price.

ğŸ’¡ Conclusion

The Linear Regression model successfully predicts house prices using selected features.

This project demonstrates the practical implementation of:

Data preprocessing

Feature selection

Regression modeling

Performance evaluation

Model interpretation

It provides hands-on experience in applying machine learning techniques to real-world datasets.

ğŸ‘©â€ğŸ’» Author

Internship Project â€“ Data Analysis / Machine Learning
Anitha Ani

# PROJECT 02(LEVEL_01)
# Marketing Analytics â€“ Customer Segmentation
ğŸ“Œ Project Title

Customer Segmentation using Data Analytics Techniques

ğŸ“– Project Description

This project focuses on analyzing customer data to perform customer segmentation for marketing analytics.

Customer segmentation helps businesses divide customers into meaningful groups based on purchasing behavior, income, spending patterns, or demographic characteristics.

The objective is to identify distinct customer groups that can help businesses design targeted marketing strategies.

The project is implemented using Python in Jupyter Notebook.

ğŸ¯ Objectives

Perform exploratory data analysis (EDA) on customer data

Clean and preprocess the dataset

Analyze customer behavior patterns

Segment customers into meaningful groups

Visualize segmentation results

Provide actionable marketing recommendations

ğŸ› ï¸ Tools & Technologies Used

Python

Jupyter Notebook

Pandas

NumPy

Matplotlib

Scikit-Learn (for clustering if used)

ğŸ“‚ Dataset Overview

The dataset contains customer-related information such as:

Customer ID

Age

Gender

Annual Income

Spending Score

Purchase behavior metrics

(Exact features depend on the dataset used in the notebook.)

ğŸ” Steps Performed
1ï¸âƒ£ Data Loading

Imported the dataset using Pandas

Displayed first few rows

Checked dataset dimensions

2ï¸âƒ£ Data Exploration

Checked data types

Identified missing values

Generated statistical summaries

Observed distribution of key features

3ï¸âƒ£ Data Cleaning

Handled missing values

Removed duplicates

Converted data types if required

4ï¸âƒ£ Exploratory Data Analysis (EDA)

Analyzed income distribution

Studied spending score patterns

Compared customer behavior across demographics

Identified trends and correlations

5ï¸âƒ£ Customer Segmentation

Customer segmentation was performed using analytical techniques such as:

Grouping based on income and spending

Clustering (e.g., K-Means if implemented)

This helps identify customer types like:

High income â€“ High spending

High income â€“ Low spending

Low income â€“ High spending

Low income â€“ Low spending

6ï¸âƒ£ Visualization

Various visualizations were created to understand patterns:

Scatter plots

Bar charts

Cluster visualizations

Distribution plots

These visuals help interpret segmentation clearly.

ğŸ“ˆ Key Insights

Customers can be divided into distinct spending groups.

High-income customers do not always spend more.

Certain customer groups offer high revenue potential.

Targeted marketing can improve business growth.

ğŸ’¡ Business Recommendations

Focus premium marketing on high-income, high-spending customers.

Offer discounts to high-income but low-spending customers.

Introduce loyalty programs for frequent buyers.

Personalize promotions based on customer segment.

âœ… Conclusion

Customer segmentation enables businesses to:

Understand customer behavior

Improve marketing efficiency

Increase customer retention

Maximize revenue

This project demonstrates how data analytics can be applied to real-world marketing strategies.

ğŸ‘©â€ğŸ’» Author

Internship Project â€“ Marketing Analytics
Anitha Ani

# PROJECT 02(LEVEL_02)
# Wine Quality Prediction using Machine Learning
ğŸ“Œ Project Title

Wine Quality Prediction using Random Forest, SGD, and Support Vector Classifier

ğŸ“– Project Description

This project aims to predict the quality of wine based on its physicochemical properties using Machine Learning classification algorithms.

The dataset used is WineQT.csv, which contains chemical attributes such as acidity, alcohol content, density, sulphates, and more.

The goal is to:

Perform data preprocessing

Conduct exploratory data analysis (EDA)

Train multiple classification models

Compare their performance

Identify the best-performing model

ğŸ“‚ Dataset Details

Dataset Name: WineQT.csv

Type: Classification Dataset

Target Variable: quality

ğŸ”¬ Features Used

Fixed Acidity

Volatile Acidity

Citric Acid

Residual Sugar

Chlorides

Free Sulfur Dioxide

Total Sulfur Dioxide

Density

pH

Sulphates

Alcohol

Quality (Output Label)

ğŸ› ï¸ Tools & Technologies

Python

Jupyter Notebook

Pandas

NumPy

Matplotlib

Seaborn

Scikit-learn

âš™ï¸ Project Workflow
1ï¸âƒ£ Data Loading

Import dataset using Pandas

Display dataset structure and summary

2ï¸âƒ£ Data Preprocessing

Check missing values

Remove unnecessary columns (if any)

Separate features (X) and target (y)

3ï¸âƒ£ Exploratory Data Analysis (EDA)

Correlation heatmap

Quality distribution analysis

Feature relationship visualization

4ï¸âƒ£ Data Splitting

Train-test split (80% training, 20% testing)

5ï¸âƒ£ Feature Scaling

StandardScaler used to normalize feature values

6ï¸âƒ£ Model Implementation

Three classification models were implemented:

ğŸŒ² Random Forest Classifier

âš¡ Stochastic Gradient Descent (SGD) Classifier

ğŸ¯ Support Vector Classifier (SVC)

7ï¸âƒ£ Model Evaluation

Accuracy Score

Confusion Matrix

Classification Report

8ï¸âƒ£ Model Comparison

Compare model accuracies

Select best performing model

ğŸ“Š Expected Output

Accuracy comparison of all three models

Confusion matrix visualization

Classification performance metrics

ğŸš€ How to Run the Notebook

Download the repository

Place WineQT.csv in the same folder as Wine_Quality.ipynb

Open Jupyter Notebook

Run all cells sequentially

ğŸ¯ Learning Outcomes

Understanding classification problems

Performing EDA effectively

Applying feature scaling

Implementing multiple ML models

Comparing and evaluating model performance

ğŸ“Œ Conclusion

This project demonstrates how machine learning algorithms can be used to predict wine quality based on chemical attributes. It emphasizes the importance of preprocessing, visualization, and model evaluation in building reliable predictive systems.

Author
internship project - Wine Quality Analysis
Anitha Ani

# PROJECT 03(LEVEL_01)
# Data Cleaning Project
ğŸ“Œ Project Title

Data Cleaning and Preprocessing for Data Analysis

ğŸ¯ Objective

The objective of this project is to clean and preprocess raw data to improve its quality, consistency, and reliability before performing data analysis or machine learning tasks.

Data cleaning ensures that the dataset is accurate, complete, and ready for further analysis.

ğŸ“– Project Description

Raw datasets often contain:

Missing values

Duplicate records

Incorrect data formats

Outliers

Inconsistent entries

This project focuses on identifying and fixing these issues using Python-based data analysis tools.

ğŸ›  Tools & Technologies Used

Python

Pandas

NumPy

Matplotlib

Seaborn

ğŸ” Data Cleaning Steps Performed
1ï¸âƒ£ Data Loading

Import dataset using Pandas

Display first few rows

Understand dataset structure

2ï¸âƒ£ Data Exploration

Check data types

View summary statistics

Identify null values

3ï¸âƒ£ Handling Missing Values

Detect missing data

Remove or fill missing values using:

Mean

Median

Mode

Forward/Backward fill

4ï¸âƒ£ Removing Duplicates

Identify duplicate rows

Drop duplicate records

5ï¸âƒ£ Data Type Conversion

Convert columns into appropriate formats

String to numeric

Object to datetime

Integer to float

6ï¸âƒ£ Handling Outliers

Detect outliers using:

Boxplots

Z-score method

IQR method

Remove or cap extreme values

7ï¸âƒ£ Feature Scaling (if required)

Normalize or standardize numeric features

ğŸ“Š Outcome

After cleaning:

Dataset becomes consistent and structured

Missing values are handled

Duplicates are removed

Data types are corrected

Dataset is ready for analysis or machine learning

ğŸš€ Importance of Data Cleaning

Data cleaning improves:

Accuracy of analysis

Model performance

Decision-making quality

Overall reliability of results

ğŸ“Œ Conclusion

Data cleaning is a crucial first step in any data analytics or machine learning project. Proper preprocessing ensures better insights and more accurate predictive models.

# PROJECT 03(LEVEL_02)
# Credit Card Fraud Detection
ğŸ“Œ Project Overview

This project focuses on detecting fraudulent credit card transactions using data analytics and machine learning techniques. The goal is to build a predictive model that can accurately identify fraud cases while minimizing false alarms.

Fraud detection is a critical application in financial security systems, helping prevent financial loss and protect customers.

ğŸ¯ Objective

The objective of this project is to:

Analyze credit card transaction data

Identify patterns that distinguish fraudulent transactions from legitimate ones

Handle class imbalance in the dataset

Build and evaluate machine learning models for fraud detection

Improve detection performance using appropriate techniques

ğŸ“‚ Dataset Information

Dataset: creditcard.csv

Total Transactions: 284,807

Features:

Time â€“ Transaction time

V1 to V28 â€“ PCA-transformed features

Amount â€“ Transaction amount

Class â€“ Target variable

0 â†’ Normal Transaction

1 â†’ Fraud Transaction

ğŸ“Œ The dataset is highly imbalanced (very few fraud cases).

ğŸ›  Technologies Used

Python

Pandas

NumPy

Matplotlib

Seaborn

Scikit-learn

ğŸ” Project Workflow
1ï¸âƒ£ Data Loading

Import dataset using Pandas

Explore dataset structure

2ï¸âƒ£ Data Cleaning

Check missing values

Remove duplicate records

Convert data types if required

3ï¸âƒ£ Exploratory Data Analysis (EDA)

Analyze class distribution

Visualize fraud vs normal transactions

Correlation analysis

4ï¸âƒ£ Data Preprocessing

Feature scaling (StandardScaler)

Drop unnecessary columns (if required)

Split data into training and testing sets

5ï¸âƒ£ Model Building

Logistic Regression

Random Forest (optional improvement)

6ï¸âƒ£ Model Evaluation

Accuracy

Precision

Recall

F1-score

Confusion Matrix

ğŸ“Œ In fraud detection, Recall and F1-score are more important than accuracy due to class imbalance.

ğŸ“Š Results

Successfully identified fraud patterns

Improved detection performance using class balancing

Achieved strong recall for fraud class

ğŸš€ Future Improvements

Apply SMOTE for better handling of imbalanced data

Use advanced models like XGBoost

Deploy model using Flask or Streamlit

Real-time fraud detection integration

ğŸ“ˆ Key Learnings

Handling imbalanced datasets

Importance of feature scaling

Evaluating classification models using proper metrics

Understanding financial fraud detection systems

ğŸ‘©â€ğŸ’» Author

Anitha Ani
Data Analytics & Machine Learning Project

# PROJECT 04(LEVEL_01)
# Sentiment Analysis using Machine Learning
ğŸ“Œ Project Overview

This project focuses on performing Sentiment Analysis on textual data to determine whether a given text expresses a positive, negative, or neutral sentiment.

Sentiment analysis is widely used in:

Product reviews

Social media monitoring

Customer feedback analysis

Market research

The project uses Natural Language Processing (NLP) techniques and Machine Learning models to classify sentiments accurately.

ğŸ¯ Objective

The main objectives of this project are:

Analyze text data and extract meaningful insights

Preprocess textual data using NLP techniques

Convert text into numerical features

Build a classification model for sentiment prediction

Evaluate model performance using appropriate metrics

ğŸ“‚ Dataset Information

Dataset: Text-based dataset (e.g., reviews, comments, or tweets)

Key Columns:

Text â†’ Input text data

Sentiment â†’ Target label (Positive / Negative / Neutral)

ğŸ›  Technologies Used

Python

Pandas

NumPy

NLTK / Scikit-learn

Matplotlib

Seaborn

ğŸ” Project Workflow
1ï¸âƒ£ Data Loading

Import dataset using Pandas

Explore dataset structure

2ï¸âƒ£ Data Cleaning

Remove null values

Remove special characters

Convert text to lowercase

Remove stopwords

Tokenization

3ï¸âƒ£ Text Preprocessing

Stemming or Lemmatization

Removing punctuation

Cleaning unnecessary whitespace

4ï¸âƒ£ Feature Extraction

Count Vectorizer

TF-IDF Vectorizer

5ï¸âƒ£ Model Building

Logistic Regression

Naive Bayes

Support Vector Machine (optional)

6ï¸âƒ£ Model Evaluation

Accuracy

Precision

Recall

F1-score

Confusion Matrix

ğŸ“Š Results

Successfully classified text into sentiment categories

Achieved good accuracy using TF-IDF features

Improved model performance after preprocessing

ğŸš€ Future Improvements

Use Deep Learning models (LSTM, BERT)

Deploy as a web app using Streamlit or Flask

Perform real-time sentiment analysis

Multi-language sentiment support

ğŸ“ˆ Applications

Customer review analysis

Brand reputation monitoring

Political sentiment tracking

Feedback analysis for businesses

ğŸ‘©â€ğŸ’» Author
Anitha Ani

# PROJECT 04(LEVEL_02)
# Unveiling the Android App Market
ğŸ“Š Analyzing Google Play Store Data
ğŸ“Œ Project Overview

This project focuses on analyzing the Google Play Store dataset to uncover insights about the Android app market. The analysis helps understand trends in app categories, user ratings, installs, pricing strategies, and user reviews.

By performing exploratory data analysis (EDA) and data cleaning, this project reveals patterns that influence app popularity and market performance.

ğŸ¯ Objective

The main objectives of this project are:

Analyze app market trends across different categories

Identify factors affecting app ratings and installs

Compare free vs paid app performance

Study user sentiment from reviews

Discover revenue and pricing patterns

ğŸ“‚ Dataset Information

The project uses two datasets:

1ï¸âƒ£ app.csv

App â€“ Application name

Category â€“ App category

Rating â€“ User rating

Reviews â€“ Number of reviews

Size â€“ App size

Installs â€“ Number of downloads

Type â€“ Free or Paid

Price â€“ App price

Content Rating â€“ Age group suitability

Genres â€“ App genre

2ï¸âƒ£ user_reviews.csv

App â€“ Application name

Translated_Review â€“ User review text

Sentiment â€“ Positive / Negative / Neutral

Sentiment_Polarity

Sentiment_Subjectivity

ğŸ›  Technologies Used

Python

Pandas

NumPy

Matplotlib

Seaborn

Scikit-learn (optional for modeling)

ğŸ” Project Workflow
1ï¸âƒ£ Data Loading

Import datasets using Pandas

Display structure and summary

2ï¸âƒ£ Data Cleaning

Handle missing values

Remove duplicate entries

Clean "Installs" column (remove + and ,)

Convert "Price" to numeric

Clean "Size" column (convert MB/KB to numeric)

3ï¸âƒ£ Exploratory Data Analysis (EDA)

Distribution of app ratings

Most popular app categories

Free vs Paid app comparison

Install trends by category

Correlation between reviews and ratings

4ï¸âƒ£ User Sentiment Analysis (Optional)

Merge review dataset with app dataset

Analyze sentiment distribution

Compare rating vs sentiment

5ï¸âƒ£ Visualization

Bar charts for top categories

Histograms for ratings and installs

Boxplots for price vs rating

Heatmap for correlations

ğŸ“Š Key Insights

Most apps on Play Store are Free

Certain categories dominate installs (e.g., Games, Tools)

Higher reviews often correlate with higher installs

Paid apps generally have higher ratings in niche categories

ğŸš€ Future Improvements

Build a prediction model for app success

Perform advanced sentiment analysis using NLP

Revenue estimation based on installs & pricing

Dashboard creation using Power BI / Tableau

Deploy as a web analytics app

ğŸ“ˆ Business Applications

Helps developers understand market demand

Assists investors in identifying profitable categories

Supports marketing strategy planning

Improves app pricing decisions

ğŸ‘©â€ğŸ’» Author

Anitha Ani
Data Analytics & Market Research Project

# PROJECT 05
# Autocomplete & Autocorrect using Data Analytics
ğŸ“Œ Project Overview

This project focuses on building an Autocomplete and Autocorrect system using data analytics and Natural Language Processing (NLP) techniques.

Autocomplete predicts the next word based on previous input, while Autocorrect detects and corrects spelling mistakes. These systems are widely used in search engines, messaging apps, and text editors.

The project demonstrates how text data can be analyzed and transformed into intelligent predictive models.

ğŸ¯ Objective

The main objectives of this project are:

Analyze text data to understand word frequency patterns

Build an Autocomplete system using probabilistic models

Implement Autocorrect using edit distance algorithms

Improve typing efficiency and user experience

Evaluate prediction accuracy

ğŸ“‚ Dataset Information

Text corpus dataset (e.g., articles, reviews, chat data)

Preprocessed text used to build vocabulary and frequency dictionary

Dataset includes:

Words and their frequencies

Sentences for language modeling

Common spelling variations

ğŸ›  Technologies Used

Python

Pandas

NumPy

NLTK

Scikit-learn (optional)

Regular Expressions

ğŸ” Project Workflow
1ï¸âƒ£ Data Collection

Load text dataset

Combine and structure raw text data

2ï¸âƒ£ Data Cleaning

Convert text to lowercase

Remove punctuation and special characters

Tokenization

Remove unwanted symbols

3ï¸âƒ£ Vocabulary Building

Create word frequency dictionary

Identify most common words

Generate probability distribution

4ï¸âƒ£ Autocomplete Implementation

Use N-gram model (Unigram, Bigram, Trigram)

Predict next word based on previous words

Rank suggestions by probability

5ï¸âƒ£ Autocorrect Implementation

Implement Edit Distance (Levenshtein Distance)

Generate candidate corrections

Choose most probable correct word

Compare input word with vocabulary

6ï¸âƒ£ Model Evaluation

Accuracy of word prediction

Correction success rate

Response time performance

ğŸ“Š Key Features

Real-time word prediction

Spelling error detection

Probability-based suggestions

Customizable vocabulary

ğŸš€ Future Improvements

Implement Deep Learning models (LSTM, Transformer)

Integrate with mobile or web application

Add multilingual support

Improve context understanding

ğŸ“ˆ Applications

Search engines

Chat applications

Email typing assistants

Code editors

Smart keyboards

ğŸ‘©â€ğŸ’» Author

Anitha Ani
Data Analytics & NLP Project
